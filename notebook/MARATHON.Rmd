---
title: "MARATHON: Integrative pipeline for profiling DNA copy number and inferring tumor phylogeny"
author: "Yuchao Jiang, Hao Chen, Gene Urrutia, Zilu Zhou, Nancy Zhang"
date: "`r format(Sys.Date())`"
abstract: >
  Copy number variation is an important and abundant source of variation in the human genome, which has been associated with a number of diseases, especially cancer. Massively parallel next-generation sequencing allows copy number profiling with fine resolution. Such efforts, however, have met with mixed successes, with setbacks arising partly from the lack of reliable analytical methods to meet the diverse and unique challenges arising from the myriad experimental designs and study goals in genetic studies. In cancer genomics, detection of somatic copy number changes and profiling of allele-specific copy number (ASCN) are complicated by experimental biases and artifacts as well as normal cell contamination and cancer subclone admixture. Furthermore, careful statistical modeling is warranted to reconstruct tumor phylogeny by both somatic ASCN changes and single nucleotide variants. Here we describe a flexible computational pipeline, MARATHON (copy nuMber vARiAtion and Tumor pHylOgeNy), which integrates multiple related statistical software for copy number profiling and downstream analyses in disease genetic studies.
output:
  rmarkdown::html_document:
    highlight: pygments
    toc: true
bibliography: MARATHON.bibtex
---

```{r setup, echo=FALSE, results="hide"}
knitr::opts_chunk$set(tidy=FALSE, cache=TRUE,
                      dev="png",
                      message=FALSE, error=FALSE, warning=TRUE)
```	


# Overview of analysis pipeline

The possible analysis scenarios are listed in Table 1. Figure 1 gives an outline for the relationship between the software: CODEX and CODEX2 perform read depth normalization for total copy number profiling; read depth normalized by CODEX/CODEX2 is received by iCNV, which combines it with allele-specific read counts and microarray data to detect CNVs; FALCON and FALCON-X perform ASCN analysis; and Canopy receives input from FALCON/FALCON-X to perform tumor phylogeny reconstruction.

```{r, out.width = "600px", fig.align = "center", echo=FALSE}
knitr::include_graphics("https://raw.githubusercontent.com/yuchaojiang/MARATHON/master/figure/Figure1.jpg")
```
**Figure 1**. A flowchart outlining the procedures for profiling CNV, ASCN, and reconstructing tumor phylogeny. CNVs with common and rare population frequencies can be profiled by CODEX and CODEX2, with and without negative control samples. iCNV integrates sequencing and microarray data for CNV detection. ASCNs can be profiled by FALCON and FALCON-X using allelic read counts at germline heterozygous loci. Canopy infers tumor phylogeny using somatic SNVs and ASCNs.

```{r, out.width = "600px", fig.align = "center", echo=FALSE}
knitr::include_graphics("https://raw.githubusercontent.com/yuchaojiang/MARATHON/master/figure/Table1.png")
```

**Table 1**. Analysis scenarios and pipeline design. The last column shows the sequencing of software that should be used for each analysis scenario. *By "normal" we mean samples that are not derived from tumor tissue. Broad copy number changes are not expected to cover the genome in the normal controls.

# Installation

**Installation Option 1**: Docker Image - Good for ease of installation
A docker image is available [here](https://hub.docker.com/r/lzeppelini/marathon/).
This image is an Rstudio GUI built on rocker/tidyverse with MARATHON as well as all of its dependent packages and datasets pre-installed. Note that this can take a while to download the human reference genome as well as the toy sequencing dataset. Instructions for using Docker can be found [here](https://docs.docker.com/get-started/).

**Installation Option 2**: Install to R/RStudio - Good for performance
Install all packages in the latest version of [R](https://www.r-project.org/).
```{r, eval=FALSE}
install.packages(c("canopy", "falcon", "falconx", "devtools"))
source("https://bioconductor.org/biocLite.R")
biocLite(c("CODEX", "WES.1KG.WUGSC"))
library(devtools)
install_github(c("yuchaojiang/CODEX2/package", "zhouzilu/iCNV/package", "yuchaojiang/MARATHON/package"))
```


# Running MARATHON

## Total copy number analysis of normal

### CODEX for data normalization and total copy number analysis in normal
CODEX [@jiang2015codex] adopts a Poisson latent factor model for normalization to remove biases due to GC content, exon capture and amplification efficiency, and latent systemic artifacts.

Get bam file directories, sample names from .txt file, and exonic positions from .bed file.

```{r, message=FALSE, warning=FALSE}
library(MARATHON, quietly = TRUE)
library(WES.1KG.WUGSC) # Load Toy data from the 1000 Genomes Project.
dirPath <- system.file("extdata", package = "WES.1KG.WUGSC")
bamFile <- list.files(dirPath, pattern = '*.bam$')
bamdir <- file.path(dirPath, bamFile)
sampname <- as.matrix(read.table(file.path(dirPath, "sampname")))
bedFile <- file.path(dirPath, "chr22_400_to_500.bed")
chr <- 22
bambedObj <- getbambed(bamdir = bamdir, bedFile = bedFile, 
                       sampname = sampname, projectname = "CODEX_demo", chr)
bamdir <- bambedObj$bamdir; sampname <- bambedObj$sampname
ref <- bambedObj$ref; projectname <- bambedObj$projectname; chr <- bambedObj$chr
```

Get read depth coverage

```{r message=FALSE}
coverageObj <- getcoverage(bambedObj, mapqthres = 20)
Y <- coverageObj$Y; readlength <- coverageObj$readlength
```

Get GC content and mappability

```{r}
gc <- getgc(chr, ref)
mapp <- getmapp(chr, ref)
```

Quality control
```{r}
qcObj <- qc(Y, sampname, chr, ref, mapp, gc, cov_thresh = c(20, 4000), 
            length_thresh = c(20, 2000), mapp_thresh = 0.9, gc_thresh = c(20, 80))
Y_qc <- qcObj$Y_qc; sampname_qc <- qcObj$sampname_qc; gc_qc <- qcObj$gc_qc
mapp_qc <- qcObj$mapp_qc; ref_qc <- qcObj$ref_qc; qcmat <- qcObj$qcmat
# write.table(qcmat, file = paste(projectname, '_', chr, '_qcmat', '.txt', sep=''),
#             sep='\t', quote=FALSE, row.names=FALSE)
```

Normalization with normal controls.

```{r message=F}
normObj <- normalize(Y_qc, gc_qc, K = 1:6)
Yhat <- normObj$Yhat; AIC <- normObj$AIC; BIC <- normObj$BIC
RSS <- normObj$RSS; K <- normObj$K
```

Choose the number of latent factors

```{r, eval=FALSE}
choiceofK(AIC, BIC, RSS, K, filename = paste(projectname, "_", chr, 
                                             "_choiceofK", ".pdf", sep = ""))
```

```{r, echo=FALSE, fig1, fig.height = 2.5, fig.width = 6, fig.align = "center"}
par(mfrow = c(1, 3))
plot(K, RSS, type = "b", xlab = "Number of latent variables", pch=20)
plot(K, AIC, type = "b", xlab = "Number of latent variables", pch=20)
plot(K, BIC, type = "b", xlab = "Number of latent variables", pch=20)
```

Poisson-likelihood recursive segmentation.
```{r message=FALSE}
optK = K[which.max(BIC)]
finalcall <- segment.recursive(Y_qc, Yhat, optK = optK, K = K, sampname_qc,
                     ref_qc, chr, lmax = 200, mode = "integer")
head(finalcall)
```


### CODEX2 for calling improvement
CODEX2 [@jiang2017codex2] builds on CODEX with a significant improvement of sensitivity for both rare and common variants.

### iCNV for calling improvement
iCNV [@zhou2017integrative] uses the normalized coverage from CODEX/CODEX2, and makes use of sequenced reads at inherited single nucleotide polymorphism (SNP) positions for CNV detection. These heterozygous loci are shown to be valuable in improving detection and genotyping accuracy. iCNV takes as input normalized coverage by CODEX/CODEX2, allelic frequency at inherited SNP positions from sequencing, and log-ratio and B-allele frequency from SNP array. Output is CNV calls with quality scores.




## Total copy number analysis of tumor

CODEX2 [@jiang2017codex2] can be applied to two scenarios: the case control scenario where the goal is to detect CNVs that are enriched in the case samples; and the scenario where control samples are not available and the goal is simply to profile all CNVs. CODEX and CODEX2 take as input assembled BAM files as well as bed files specifying targets for WES and targeted sequencing and output normalized read counts and tab-delimited text files with copy number calls.


## Tumor allele-specific copy number by WGS

For allele-specific copy number estimation in a matched tumor-normal setting, FALCON [@chen2014allele] is based on a change-point model on a process of a mixture of two bivariate Binomial distributions. FALCON takes as input allelic read counts at germline heterozygous loci and outputs ASCN estimates with genome segmentations. 

Calculate depth ratio (total read counts of tumor versus normal). Restrict our analysis to chromosome 14, where a copy-neutral loss of heterozygosity has been previously reported.
```{r}
coverageData = relapse.demo
rdep=sum(coverageData$Tumor_ReadCount_Total)/sum(coverageData$Normal_ReadCount_Total)
chr = 14
coverageChr=coverageData[which(coverageData[,'Chromosome']==chr),]
```

Remove variants with missing genotype.
```{r}
nonMissing1 = coverageChr[,'Match_Norm_Seq_Allele1']!=' '
nonMissing2 = coverageChr[,'Match_Norm_Seq_Allele2']!=' '
nonMissing3 = coverageChr[,'Reference_Allele']!=' '
nonMissing4 = coverageChr[,'TumorSeq_Allele1']!=' '
nonMissing5 = coverageChr[,'TumorSeq_Allele2']!=' '
coverageChr=coverageChr[nonMissing1 & nonMissing2 & nonMissing3 & nonMissing4 & nonMissing5,]
```
  
Get germline heterozygous loci where normal allele1 differs from normal allele2.
```{r}
coverageChrHet=coverageChr[(as.matrix(coverageChr[,'Match_Norm_Seq_Allele1'])!=as.matrix(coverageChr[,'Match_Norm_Seq_Allele2'])),]
```
  
QC procedures to remove false neg and false pos variants. The thresholds can be adjusted.

```{r}
# Remove indels (this can be relaxed but we think indels are harder to call than SNPs).
indelThresh = 1
indel.filter1=nchar(as.matrix(coverageChrHet[,'Reference_Allele']))<=indelThresh
indel.filter2=nchar(as.matrix(coverageChrHet[,'Match_Norm_Seq_Allele1']))<=indelThresh
indel.filter3=nchar(as.matrix(coverageChrHet[,'Match_Norm_Seq_Allele2']))<=indelThresh
indel.filter4=nchar(as.matrix(coverageChrHet[,'TumorSeq_Allele1']))<=indelThresh
indel.filter5=nchar(as.matrix(coverageChrHet[,'TumorSeq_Allele2']))<=indelThresh
coverageChrHet=coverageChrHet[indel.filter1 & indel.filter2 & indel.filter3 & indel.filter4 & indel.filter5,]

# Filter on coverage: total number of reads greater than 30 in both tumor and normal.
coverageThresh = 30
depth.filter1=(coverageChrHet[,"Normal_ReadCount_Ref"]+coverageChrHet[,"Normal_ReadCount_Alt"])>=coverageThresh
depth.filter2=(coverageChrHet[,"Tumor_ReadCount_Ref"]+coverageChrHet[,"Tumor_ReadCount_Alt"])>=coverageThresh
coverageChrHet=coverageChrHet[depth.filter1 & depth.filter2,]
```  
  
Generat input for FALCON (data frame with four columns), run FALCON, and view FALCON's segmentation.

```{r message=FALSE, results=FALSE, fig.align = "center"}
readMatrix=as.data.frame(coverageChrHet[,c('Tumor_ReadCount_Ref',
                                                   'Tumor_ReadCount_Alt',
                                                   'Normal_ReadCount_Ref',
                                                   'Normal_ReadCount_Alt')])
colnames(readMatrix)=c('AT','BT','AN','BN')
tauhat = getChangepoints(readMatrix)
cn = getASCN(readMatrix, tauhat=tauhat, rdep = rdep, threshold = 0.3)
view(cn, pos=coverageChrHet[,'Start_position'], rdep = rdep)
```

From the figure above, we see that: (1) There are small segments that need to be removed; (2) Consecutive segments with similar allelic copy number states need to be combined. Therefore, we need to further curate FALCON's segmentation results.
  
```{r, fig.align = "center"}
if(length(tauhat)>0){
  length.thres=10^6  # Threshold for length of segments, in base pair.
  delta.cn.thres=0.3  # Threshold of absolute copy number difference between consecutive segments.
  falcon.qc.list = falcon.qc(readMatrix = readMatrix,
                             tauhat = tauhat,
                             cn = cn,
                             st_bp = coverageChrHet[,"Start_position"],
                             end_bp = coverageChrHet[,"End_position"],
                             rdep = rdep,
                             length.thres = length.thres,
                             delta.cn.thres = delta.cn.thres)
  tauhat=falcon.qc.list$tauhat
  cn=falcon.qc.list$cn
}
# Chromosomal view of QC'ed segmentation results.
view(cn,pos=coverageChrHet[,'Start_position'], rdep = rdep)
```

The code below is to generate table output including genomic locations for segment boudaries, as well as mean and standard deviation for each segment. For Canopy's input, we use Bootstrap-based method to estimate the standard deviations for the allele-specific copy numbers.

```{r}  
  falcon.output=falcon.output(readMatrix = readMatrix,
                              tauhat = tauhat,
                              cn = cn,
                              st_bp = coverageChrHet[,"Start_position"],
                              end_bp = coverageChrHet[,"End_position"],
                              nboot = 5000)
  falcon.output = cbind(chr=rep(chr,nrow(falcon.output)), falcon.output)
  falcon.output
```  




## Tumor allele-specific copy number by WES

For WES data, biases and artifacts cannot be fully captured by comparing the tumor sample to the matched normal sample. FALCON-X [@chen2017allele] extends upon FALCON, where it takes as inputs allelic read counts at germline heterozygous loci and total coverage biases for each of these loci estimated by CONDEX2 and outputs ASCN estimates.









## Tumor phylogeny analysis by WGS/WES

Canopy [@jiang2016assessing] identifies subclones within a tumor, determines the mutational profiles of these subclones, and infers the tumor's phylogenetic history by NGS data from temporally and/or spatially separated tumor resections from the same patient. Canopy jointly models somatic copy number changes and SNVs in a similar fashion to non-negative matrix factorization and adopts a Bayesian framework to reconstruct phylogeny with posterior confidence assessment. Canopy takes as input both somatic ASCN changes returned by FALCON/FALCON-X as well as somatic SNVs and outputs tumor phylogenetic trees with somatic mutations placed along tree branches and subclones placed at the leaves. 


# Session info

```{r sessionInfo}
sessionInfo()
```

# References